
\section{Задание}

Разработать поисковую систему по собственному корпусу документов морской тематики, включающую:
\begin{itemize}
    \item поискового робота (crawler) для сбора документов из открытых источников;
    \item хранение документов в базе данных;
    \item индексатор с токенизацией и стеммингом;
    \item построение булевого индекса;
    \item реализацию булевого поиска с поддержкой операторов AND, OR, NOT и скобок;
    \item экспериментальный анализ свойств корпуса (в том числе закон Ципфа).
\end{itemize}

\section{Корпус и источники данных}

Корпус собран по морской тематике и состоит из двух независимых источников. Я специально выбрал морскую тематику, потому что по ней легко найти много текстов, но при этом термины достаточно специфичные (встречаются слова про суда, порты, океан, офшор, экологию и т.д.), что удобно для проверки поиска и индексации.

\begin{itemize}
    \item \textbf{Wikipedia EN} --- статьи английской Википедии из тематических категорий, связанных с морем, океанографией, судоходством, морской экологией и портовой инфраструктурой. Этот источник в основном даёт ``энциклопедические'' тексты: они обычно длинные, структурированные, содержат определения, перечисления, факты и ссылки на связанные понятия. Это полезно, потому что в таких текстах часто встречаются устойчивые термины и много разных словоформ.
    
    \item \textbf{MarineLink} --- новостные публикации портала MarineLink (раздел Maritime News), посвящённые отраслевым событиям: суда, офшор, порты, логистика, судостроение, безопасность, экология. Этот источник даёт более ``живые'' новости: тексты короче, часто содержат имена компаний, названия судов, даты, географические объекты и отраслевую лексику. В таких документах обычно меньше ``общих'' слов и больше специфики.
\end{itemize}

Корпус является тематически однородным (везде морская тематика), но источники различаются по стилю и структуре. Википедия чаще даёт подробные описания и справочную информацию, а новости MarineLink --- события и контекст вокруг них. Это удобно для лабораторных работ, потому что можно проверить, как система работает на документах разного типа: где-то текст длинный и насыщенный терминами, а где-то короткий, но содержит много конкретных сущностей.

Также важно, что источники независимые: это снижает риск того, что корпус получится ``однообразным''. В дальнейшем это помогает лучше увидеть проблемы токенизации (например, дефисы, сокращения, имена), стемминга (словоформы и редкие слова) и булевого поиска (когда нужный термин встречается в разных стилях текста).


\section{Формат сырых документов и выделение текста}

Сырые документы сохраняются в виде отдельных файлов в формате JSON (один файл --- один документ). Такой формат я выбрал, потому что он простой, удобен для отладки и легко читается любым скриптом. При необходимости можно быстро посмотреть любой документ руками и понять, что именно скачалось.

Каждый документ содержит основные поля:
\begin{itemize}
    \item \texttt{source} --- источник (wikipedia\_en / marinelink), чтобы потом можно было разделять документы по источникам и анализировать их отдельно;
    \item \texttt{url} --- нормализованный URL. Нормализация нужна, чтобы избежать дублей (например, если одна и та же страница встречается с разными параметрами или с якорями);
    \item \texttt{title} --- заголовок страницы, он полезен как мета-информация и для отображения в поисковой выдаче;
    \item \texttt{raw\_html} --- исходный HTML-код страницы, то есть ``как скачали'' (это нужно для воспроизводимости и для того, чтобы при необходимости можно было заново выделить текст другими правилами);
    \item служебные поля (например, время обкачки в Unix timestamp, идентификатор документа, иногда дополнительные заголовки), которые помогают понимать, когда документ был скачан и можно ли его переобкачивать.
\end{itemize}

Дальше для лабораторных работ по индексации и поиску нужен именно текст, поэтому из HTML выделяется plain-text. Я делал это отдельным шагом, чтобы:
\begin{itemize}
    \item отделить сбор данных от обработки текста;
    \item получить единый формат документов для всех следующих лабораторных;
    \item уменьшить объём данных (в HTML много лишнего, а для поиска нужен текст).
\end{itemize}

При извлечении текста применялись базовые правила очистки:
\begin{itemize}
    \item удаляются теги \texttt{script/style/noscript}, чтобы в тексте не было кода, стилей и других технических вставок;
    \item для Wikipedia извлекается основной контент статьи (без навигации, меню и служебных блоков);
    \item для MarineLink извлекается заголовок и основной текст новости, а также убираются элементы шаблона сайта (например, блоки рекомендаций и похожих новостей).
\end{itemize}

Важно, что извлечённый текст сохраняется отдельно как \texttt{.txt} в кодировке UTF-8 (один файл --- один документ). Это удобно по нескольким причинам:
\begin{itemize}
    \item дальше можно обрабатывать документы потоково (читать по одному файлу), не загружая всё в память;
    \item легко пересобирать индекс или пересчитывать статистики, не обращаясь заново к ``сырым'' HTML;
    \item текстовые файлы проще использовать для отладки токенизации/стемминга, потому что видно исходный материал.
\end{itemize}

Таким образом, получилось два уровня данных: ``сырой'' слой (HTML в JSON) для воспроизводимости и ``чистый'' слой (plain-text), который используется в последующих лабораторных работах.


\section{Статистика корпуса}

\begin{table}[h!]
\centering
\begin{tabular}{|l|r|r|}
\hline
\textbf{Характеристика} & \textbf{Wikipedia EN} & \textbf{MarineLink} \\
\hline
Количество документов & 32\,991 & 5\,151 \\
\hline
Размер сырых данных (HTML) & 2.95~GB & 368.6~MB \\
\hline
Размер выделенного текста & 544.8~MB & 27.8~MB \\
\hline
Средний размер сырого документа & 93.7~KB & 73.3~KB \\
\hline
Средний размер текста & 16.9~KB & 5.53~KB \\
\hline
Коэффициент ``сжатия'' (text/raw) & 18.0\% & 7.55\% \\
\hline
\end{tabular}
\caption{Статистика корпуса по источникам}
\end{table}

Итого в корпусе 38\,142 документа общим объёмом 3.31~GB сырых HTML-данных, из которых извлечено 572.6~MB текста.

\section{Существующие поисковики и примеры запросов}

Для выбранных источников доступны внешние поисковые системы:
\begin{itemize}
    \item встроенный поиск Wikipedia (по статьям en.wikipedia.org);
    \item поиск Google с ограничениями \texttt{site:en.wikipedia.org} и \texttt{site:marinelink.com}.
\end{itemize}

Примеры запросов и наблюдаемые недостатки выдачи:

\begin{enumerate}
    \item \textbf{Запрос:} \texttt{site:en.wikipedia.org ocean pollution microplastics}\\
    \textbf{Недостатки:} в выдаче часто доминируют общие статьи (``Ocean'', ``Pollution'') без ранжирования по тематике; встречаются страницы-списки и служебные страницы, которые хуже подходят как ответы.

    \item \textbf{Запрос:} \texttt{site:marinelink.com offshore wind installation vessel}\\
    \textbf{Недостатки:} результаты могут содержать несколько очень похожих новостей, а также материалы не из раздела Maritime News; часть результатов зависит от SEO и даты публикации, а не от точного соответствия запросу.

    \item \textbf{Запрос:} \texttt{site:en.wikipedia.org tension-leg platform offshore}\\
    \textbf{Недостатки:} при наличии редких терминов выдача может включать нерелевантные страницы, где термины встречаются только в ссылках/примечаниях; иногда полезные статьи находятся глубже из-за особенностей ранжирования.

    \item \textbf{Запрос:} \texttt{site:marinelink.com tanker accident investigation}\\
    \textbf{Недостатки:} результаты чувствительны к формам слов (accident/accidents), иногда лучше работает поиск по точной фразе; также встречаются страницы с неполным контентом (короткие анонсы).
\end{enumerate}

Вывод: существующие поисковики позволяют подтвердить пригодность корпуса (по обоим источникам есть доступный поиск), однако выдача не всегда удовлетворяет требованиям по точности и контролю логики поиска, что мотивирует реализацию собственной поисковой системы.

\section{Краткое описание решения}

Поисковая система реализована как набор отдельных программ (утилит) командной строки и простой веб-интерфейс. Такой подход я выбрал специально: каждую часть можно запускать отдельно, проверять результат и при необходимости переделывать, не ломая весь проект.

\begin{itemize}
    \item \textbf{Lab01:} загрузка корпуса из двух источников (Wikipedia EN, MarineLink). На этом этапе я сохраняю ``сырые'' страницы (HTML) и отдельно выделенный текст. Это нужно, чтобы можно было в любой момент перепроверить качество извлечения текста или повторно обработать данные другими правилами.
    
    \item \textbf{Lab02:} поисковый робот (crawler), который умеет скачивать документы по конфигу и складывать их в базу данных SQLite. Робот работает с задержкой между запросами, чтобы не перегружать сайт. Также его можно остановить и потом продолжить работу с того места, где он остановился. Для переобкачки предусмотрена проверка изменения документа, чтобы не скачивать одно и то же бесконечно.
    
    \item \textbf{Lab03--Lab04:} токенизация и стемминг (реализованы на C++). Эти утилиты читают тексты документов и разбивают их на токены по простым правилам. Для стемминга применяется сведение словоформ к основе, чтобы поиск был менее чувствителен к разным формам слова. Дополнительно программы выводят статистику (сколько токенов получилось, средняя длина токена, время работы и скорость).
    
    \item \textbf{Lab05:} закон Ципфа. На основе частотного словаря строится график распределения частот терминов по рангу в логарифмической шкале и сравнивается с моделью $f(r) = C/r$. В отчёте отдельно описываются причины расхождений (тематика корпуса, смешивание источников, редкие термины и т.д.).
    
    \item \textbf{Lab07:} построение булевого инвертированного индекса. Индекс хранит для каждого термина список документов, где этот термин встречается. Индекс сохраняется на диск, чтобы поиск мог работать без повторной обработки текста.
    
    \item \textbf{Lab08:} булев поиск с поддержкой AND/OR/NOT и скобок. Поиск реализован как CLI-утилита (удобно для тестов) и как веб-страница (удобно показывать результат). В веб-интерфейсе выдача группируется по источникам (Wikipedia слева, MarineLink справа), чтобы было проще сравнивать результаты.
\end{itemize}

Обработка данных организована потоково: документы читаются по одному файлу, а индекс строится без необходимости загружать весь корпус в оперативную память. Это позволяет применять решение к корпусам порядка десятков тысяч документов и выше, при условии что хватает места на диске для сохранения исходных данных и индекса.


\section{Лабораторная работа 2. Поисковый робот}

\subsection{Цель работы}
Цель лабораторной --- реализовать поискового робота (crawler), который обходит страницы из заданных источников, скачивает HTML и сохраняет документы в базу данных. Робот должен уметь:
\begin{itemize}
    \item запускаться с единственным аргументом --- путь до YAML-конфига;
    \item сохранять в БД нормализованный URL, сырой HTML, источник документа и время обкачки (Unix timestamp);
    \item корректно продолжать работу после остановки;
    \item периодически переобкачивать документы и обновлять их только если содержимое изменилось.
\end{itemize}

\subsection{Формат конфига (YAML)}
Робот запускается командой вида:
\begin{verbatim}
python robot.py config.yaml
\end{verbatim}

В конфиге есть как минимум две секции:
\begin{itemize}
    \item \texttt{db} --- настройки базы данных (например, путь к SQLite-файлу);
    \item \texttt{logic} --- настройки логики робота (задержка между запросами, параметры переобкачки и т.п.).
\end{itemize}

Также в конфиге можно задавать дополнительные параметры, которые нужны для работы: стартовые URL, лимиты, таймауты, user-agent и т.д. Я вынес это в конфиг, чтобы можно было менять поведение робота без изменения кода.

\subsection{Хранение данных}
В качестве БД я использовал SQLite, потому что она не требует отдельного сервера и хранится в одном файле, что удобно для запуска на разных машинах. Для объёма уровня десятков тысяч документов этого достаточно.

В базе данных используется две основные таблицы:
\begin{itemize}
    \item \texttt{docs} --- таблица уже скачанных документов;
    \item \texttt{frontier} --- очередь URL на скачивание и переобкачку.
\end{itemize}

В таблице \texttt{docs} сохраняются поля:
\begin{itemize}
    \item \texttt{url} --- нормализованный URL;
    \item \texttt{source} --- источник (wikipedia\_en / marinelink);
    \item \texttt{html} --- сырой HTML страницы;
    \item \texttt{fetched\_at} --- время обкачки в формате Unix timestamp;
    \item дополнительные поля для проверки изменений (например, \texttt{etag}, \texttt{last\_modified}, \texttt{content\_hash}).
\end{itemize}

\subsection{Нормализация URL}
Перед добавлением URL в очередь я нормализую ссылки: убираю якорь (часть после \#), стараюсь удалять очевидные трекинговые параметры (например, \texttt{utm\_*}) и привожу ссылку к единому виду. Это нужно, чтобы одна и та же страница не попадала в базу несколько раз под разными вариантами URL.

\subsection{Остановка и продолжение работы}
Робота можно остановить в любой момент (например, Ctrl+C). Поскольку данные пишутся в SQLite по мере работы, состояние не теряется: скачанные документы уже лежат в \texttt{docs}, а оставшиеся URL находятся в \texttt{frontier}.

При повторном запуске робот продолжает работу: он берёт следующий URL из \texttt{frontier} и продолжает обход. Таким образом, не нужно начинать скачивание заново.

\subsection{Переобкачка документов}
Чтобы робот мог обновлять документы, я сделал простую переобкачку. Для каждого документа хранится информация, по которой можно понять, изменился он или нет:
\begin{itemize}
    \item если сервер отдаёт \texttt{ETag} или \texttt{Last-Modified}, они сохраняются и используются при следующей проверке;
    \item дополнительно (или вместо этого) считается хеш от HTML, чтобы надёжно определить изменение.
\end{itemize}

Если документ не изменился, то HTML не перезаписывается, а робот просто фиксирует, что проверка выполнена. Если документ изменился, то в базе обновляются HTML и время обкачки.

\subsection{Итог}
В результате получился робот, который скачивает документы из открытых источников, сохраняет ``сырые'' страницы в базу данных, умеет продолжать работу после остановки и поддерживает переобкачку документов только при изменениях. Это даёт основу для дальнейших лабораторных работ: выделение текста, индексация и поиск.



\section{Лабораторная работа 3. Токенизация}

\subsection{Правила токенизации}
Токенизация сделана максимально простой, чтобы её было легко проверить и чтобы она работала быстро на большом количестве текстов. По сути программа проходит по строке и выделяет ``слова'' как непрерывные последовательности допустимых символов.

Используются такие правила:
\begin{itemize}
    \item весь текст переводится в нижний регистр, чтобы \texttt{Sea} и \texttt{sea} считались одним и тем же;
    \item токеном считается последовательность букв латиницы и цифр (\texttt{a-z, 0-9});
    \item все остальные символы считаются разделителями: пробелы, знаки препинания, скобки, кавычки, служебные символы и т.д.;
    \item токены короче 2 символов отбрасываются, так как они чаще всего создают шум (например, одиночные буквы, обрывки слов и т.п.).
\end{itemize}

Такой подход хорошо подходит именно для лабораторных работ, потому что он предсказуемый: если посмотреть на текст, можно легко понять, какие токены получится на выходе.

\subsection{Достоинства и недостатки}
Плюсы выбранного метода:
\begin{itemize}
    \item реализация простая и быстрая, её удобно применять в потоковой обработке (файл за файлом);
    \item после выделения текста из HTML остаётся мало мусора, и токенизация даёт достаточно чистые термы;
    \item получается воспроизводимый словарь терминов, который удобно использовать дальше при построении индекса.
\end{itemize}

Минусы и ограничения:
\begin{itemize}
    \item составные слова и термины с дефисами распадаются на части (например, \texttt{deep-sea} превращается в \textit{deep} и \textit{sea}), из-за этого иногда теряется смысл именно как ``единого термина'';
    \item аббревиатуры и маркировки обрабатываются не идеально (например, в морской тематике встречаются названия типа \texttt{IMO-1234567} или \texttt{AHTS}, где дефисы и формат важны);
    \item числовые токены иногда создают шум (годы, номера, размеры), но полностью выбрасывать числа тоже нельзя, потому что иногда они несут смысл.
\end{itemize}

Примеры неудачных случаев:
\begin{itemize}
    \item \textit{``co2''} и \textit{``co-2''} превращаются в разные последовательности, хотя по смыслу это одно и то же;
    \item \textit{``shipowner's''} $\rightarrow$ \textit{shipowner}, \textit{s} (лишний токен \textit{s} не несёт смысла).
\end{itemize}

Как можно было бы улучшить правила в будущем:
\begin{itemize}
    \item добавить отдельное правило для апострофа, чтобы \texttt{'s} отрезалось корректно;
    \item разрешить дефис внутри токена для некоторых случаев (например, если вокруг дефиса буквы);
    \item сделать фильтрацию чисел по простым эвристикам (например, выбрасывать слишком длинные числа или номера без букв).
\end{itemize}

\subsection{Статистика}
После токенизации по всему корпусу получаются базовые характеристики, которые нужны для последующих лабораторных работ:
\begin{itemize}
    \item общее количество токенов (сколько всего слов получилось);
    \item средняя длина токена (примерно показывает ``среднюю длину слова'' в корпусе).
\end{itemize}

Для корпуса морской тематики значения находятся в ожидаемом диапазоне: средняя длина токена получается около 5 символов, а общее количество токенов --- десятки миллионов. Эти значения логично зависят от того, насколько длинные документы, и от того, насколько сильно в текстах встречаются специальные термины и имена собственные.


\section{Лабораторная работа 4. Стемминг}

\subsection{Метод}
Для английского языка я добавил стемминг --- это упрощённое приведение слов к основе. Идея в том, что разные формы одного слова должны восприниматься как ``почти одно и то же''. Это полезно для поиска, потому что пользователь может ввести слово в одной форме, а в документах оно встречается в другой.

Стемминг сделан на основе набора правил (суффиксные преобразования). Примерно это выглядит так:
\textit{shipping} $\rightarrow$ \textit{ship}, \textit{pollution} $\rightarrow$ \textit{pollut}, \textit{fishing} $\rightarrow$ \textit{fish} и т.п.
То есть отрезаются частые окончания и суффиксы, которые обычно не меняют смысл, но меняют форму слова.

\subsection{Влияние на словарь и поиск}
После добавления стемминга я заметил два основных эффекта:
\begin{itemize}
    \item \textbf{словарь становится меньше}, потому что разные словоформы склеиваются в одну ``основу'';
    \item \textbf{поиск становится более гибким}: запрос по одному слову чаще находит документы, даже если в тексте другая форма (например, \textit{ship} и \textit{shipping}).
\end{itemize}

При этом у метода есть минус: иногда разные слова могут случайно стать одинаковыми после стемминга. Это происходит потому, что стемминг не понимает смысл, он просто применяет правила к окончаниям. В редких случаях это может давать лишние документы в выдаче (то есть снижать точность), но для уровня ``удовлетворительно'' такой подход считается нормальным.

\subsection{Производительность}
Стемминг почти всегда работает медленнее чистой токенизации, потому что после выделения токена нужно ещё прогнать его через набор правил и сделать несколько проверок суффиксов. Поэтому время обработки увеличивается, а скорость (в KB/s) падает.

Ниже приведены итоговые показатели для корпуса, чтобы можно было сравнить токенизацию и стемминг на одинаковом объёме текста.

\textbf{Tokenizer (Lab03)}
\begin{itemize}
    \item files: 38142
    \item input\_kb: 424176
    \item total\_tokens: 59284975
    \item avg\_token\_len: 5.36174
    \item time\_s: 3.771
    \item speed\_kb\_s: 112487.3
\end{itemize}

\textbf{Stemming (Lab04)}
\begin{itemize}
    \item files: 38142
    \item input\_kb: 424176
    \item total\_tokens: 59284975
    \item avg\_token\_len: 5.06492
    \item time\_s: 6.415
    \item speed\_kb\_s: 66124.7
\end{itemize}

Из сравнения видно, что стемминг уменьшает среднюю длину токена (часть окончаний отрезается) и заметно увеличивает время обработки. При этом производительности всё равно хватает для обработки десятков тысяч документов и дальнейшей потоковой индексации, то есть практическое применение на корпусе такого размера остаётся удобным.

\section{Лабораторная работа 5. Закон Ципфа}

\subsection{Построение распределения}
Для проверки закона Ципфа я сначала строю частотный словарь по всему корпусу. То есть для каждого термина считаю, сколько раз он встретился в документах (после токенизации, а при необходимости и после стемминга).

Дальше действия простые:
\begin{enumerate}
    \item Собираю пары \texttt{термин $\rightarrow$ частота}.
    \item Сортирую термины по убыванию частоты.
    \item Самому частому термину присваиваю ранг 1, следующему ранг 2 и так далее.
    \item Строю график ``частота от ранга'' в логарифмической шкале (log-log), потому что обычный график получается слишком ``скошенным'' и по нему трудно сравнивать.
\end{enumerate}

Такой график удобен тем, что если распределение близко к Ципфу, то в log-log масштабе получается почти прямая линия на заметном участке.

\subsection{Сравнение с законом Ципфа}
Закон Ципфа в простом виде говорит, что частота термина примерно обратно пропорциональна его рангу:
\[
f(r) \approx \frac{C}{r},
\]
где $r$ --- ранг термина, $f(r)$ --- частота, $C$ --- некоторая константа.

На практике идеального совпадения не бывает, и это нормально. В моём корпусе я заметил такие причины отклонений:
\begin{itemize}
    \item \textbf{верх графика (самые частые слова)} портится тем, что корпус тематический: кроме обычных частотных слов появляются ``доменные'' слова, которые встречаются часто именно из-за темы (например, ship/port/marine и т.п.). Также влияет то, что Wikipedia и MarineLink по объёму разные.
    \item \textbf{хвост графика (редкие слова)} получается более ``тяжёлым'', потому что в морской тематике много редких сущностей: названия судов, имена людей, географические точки, аббревиатуры, коды и т.д. Они часто встречаются один-два раза и сильно увеличивают хвост.
    \item \textbf{правила токенизации} тоже влияют: я отбрасываю токены длиной 1 символ, и из-за этого меняется распределение самых частых ``мусорных'' токенов. Также дефисы/апострофы могут разбивать слова на части, и это добавляет редких токенов.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{img/zipf_plot.png}
    \caption{Распределение терминов по частотам и закон Ципфа (log-log)}
    \label{fig:zipf}
\end{figure}

В целом график получается близок к прямой линии в log-log масштабе, то есть закон Ципфа для корпуса в общем работает. Отклонения в начале и в хвосте объясняются тематикой корпуса, смешиванием двух разных источников и особенностями токенизации.

\section{Лабораторная работа 7. Булев индекс}

\subsection{Построение инвертированного индекса}
Для булевого поиска нужен инвертированный индекс. Идея простая: вместо того чтобы каждый раз пробегать по всем документам, мы заранее строим структуру вида
``термин $\rightarrow$ список документов'', где этот термин встречается.

Построение индекса я делаю так:
\begin{itemize}
    \item по очереди читаю каждый текстовый файл документа;
    \item прогоняю текст через токенизацию и стемминг, чтобы дальше работать с едиными терминами;
    \item для каждого полученного термина добавляю текущий \texttt{docID} в список документов этого термина.
\end{itemize}

Важный момент: внутри одного документа одно и то же слово может встречаться много раз, но для булевого индекса это не важно. Поэтому я добавляю \texttt{docID} в postings list без повторов внутри документа. Это уменьшает размер индекса и ускоряет операции пересечения/объединения при поиске.

\subsection{Хранение}
Индекс сохраняется на диск, чтобы потом поиск работал быстро и не требовал пересборки.

Файлы индекса разделены на несколько частей:
\begin{itemize}
    \item \texttt{docs.tsv} --- таблица соответствия \texttt{docID} и документа. Я храню там источник и путь к текстовому файлу. Это нужно для выдачи результатов: поиск возвращает docID, а по нему можно понять, какой это документ.
    \item \texttt{dict.tsv} --- словарь терминов. Для каждого термина хранится, где именно в бинарном файле начинаются его postings и какой длины этот список. Так поиск может быстро открыть нужный участок \texttt{postings.bin}.
    \item \texttt{postings.bin} --- бинарный файл со списками docID. Списки лежат в отсортированном виде, потому что булевы операции (AND/OR) проще и быстрее делать именно на отсортированных списках.
\end{itemize}

Такое разбиение удобно тем, что словарь можно читать отдельно, а большие списки документов хранить компактно в бинарном виде. Это также упрощает масштабирование: даже если документов станет больше, поиск всё равно открывает только те postings, которые нужны под конкретный запрос.

\subsection{Замечания по масштабированию}
Построение индекса выполняется потоково: документы обрабатываются по одному, поэтому не нужно загружать весь корпус в память. Основная память уходит на словарь терминов и рабочие структуры при сборке. В целом подход подходит для десятков тысяч документов, а при аккуратной реализации и для большего объёма, если хватает места на диске под индекс.

\section{Лабораторная работа 8. Булев поиск}

\subsection{Логика поиска}
В этой лабораторной я реализовал булев поиск по уже построенному инвертированному индексу. Смысл булевого поиска в том, что пользователь задаёт логическое выражение, а система возвращает документы, которые этому выражению удовлетворяют.

Поддерживаются операторы:
\begin{itemize}
    \item \textbf{AND} --- пересечение множеств документов (оба слова должны быть в документе);
    \item \textbf{OR} --- объединение (достаточно, чтобы было хотя бы одно слово);
    \item \textbf{NOT} --- исключение (убираем документы, где встречается слово справа);
    \item \textbf{скобки} --- позволяют явно задать порядок вычисления.
\end{itemize}

Чтобы запрос работал правильно, его нужно разобрать (распарсить). Я делаю это так:
\begin{itemize}
    \item сначала строка запроса превращается в список токенов запроса (слова, AND/OR/NOT, скобки);
    \item дальше выражение приводится к удобному виду для вычисления (например, в ОПН/постфиксную форму);
    \item затем выражение вычисляется над postings lists.
\end{itemize}

Операции AND/OR выполняются на отсортированных списках \texttt{docID} с помощью простого двухуказательного алгоритма: это быстро и не требует лишней памяти. Для NOT берётся множество всех документов и из него вычитается список документов термина справа.

Примеры запросов:
\begin{itemize}
    \item \texttt{offshore AND sea} --- документы, где встречаются оба термина;
    \item \texttt{sponge OR star} --- документы, где есть хотя бы один из терминов;
    \item \texttt{(sponge AND star) OR (offshore AND sea)} --- комбинированный запрос со скобками;
    \item \texttt{ship AND NOT war} --- пример запроса с исключением (NOT).
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{img/searchnotweb.jpg}
    \caption{Пример поиска}
    \label{fig:web2}
\end{figure}

Важно, что такие запросы удобно использовать для проверки индекса: результат должен быть логически понятен (например, AND даёт меньше документов, чем OR).

\subsection{Интерфейс}
Чтобы было удобно и тестировать, и показывать работу, я сделал два интерфейса:

\begin{itemize}
    \item \textbf{Утилита командной строки \texttt{boolsearch}} --- принимает запрос и выводит количество найденных документов и список результатов. Этот вариант удобен для отладки и для автотестов, потому что вывод легко сравнивать.
    \item \textbf{Веб-интерфейс (Flask)} --- простая HTML-страница с формой поиска. Вводится запрос, затем показывается выдача.
\end{itemize}

В веб-интерфейсе я дополнительно разделил результаты по источникам: Wikipedia показывается в одной колонке, MarineLink --- в другой. Это удобно, потому что источники сильно разные по стилю, и можно быстро увидеть, откуда берутся найденные документы.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{img/harbor.jpg}
    \caption{Веб-интерфейс: пример запроса и выдачи (пример 1)}
    \label{fig:web1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{img/search.jpg}
    \caption{Веб-интерфейс: пример запроса и выдачи (пример 2)}
    \label{fig:web2}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{img/sponge.jpg}
    \caption{Веб-интерфейс: пример запроса и выдачи со скобками (пример 3)}
    \label{fig:web3}
\end{figure}

\section{План тестирования}

Ниже приведён план тестирования, который я использовал, чтобы убедиться, что каждая часть проекта работает правильно. Идея простая: после каждого шага должен быть понятный результат (файлы/вывод/записи в БД), который можно быстро проверить.

\subsection{Lab01}
\begin{itemize}
    \item \textbf{Проверка структуры данных.} Проверить, что после скачивания появились папки для обоих источников и в них лежат файлы (сырые документы и отдельно тексты).
    \item \textbf{Проверка двух источников.} Убедиться, что в корпусе реально присутствуют документы из Wikipedia и из MarineLink (например, по названиям папок или по полю \texttt{source} в JSON).
    \item \textbf{Проверка выделенного текста.} Открыть несколько случайных \texttt{.txt} файлов и убедиться, что это действительно текст статьи/новости, а не мусор (меню, реклама, пустые строки).
    \item \textbf{Проверка минимальной длины.} Проверить, что тексты не пустые и проходят минимальный порог длины (если используется фильтр по символам).
\end{itemize}

\subsection{Lab02}
\begin{itemize}
    \item \textbf{Проверка первого запуска.} Запустить робота на небольшом количестве URL и проверить, что в SQLite создалась база и таблицы, и что появились записи о документах.
    \item \textbf{Проверка корректности записи.} Проверить несколько записей в БД: что сохраняются url, source, время обкачки и html.
    \item \textbf{Остановка и продолжение.} Во время работы остановить робота (Ctrl+C), затем запустить снова и убедиться, что он продолжает работу, а не начинает заново.
    \item \textbf{Проверка повторной обкачки.} Запустить робота повторно и убедиться, что уже скачанные страницы не перекачиваются бесконечно, а обновляются только при необходимости (если документ изменился).
    \item \textbf{Проверка устойчивости.} Убедиться, что при сетевых ошибках робот не падает полностью, а пропускает проблемные URL или пытается повторить позже.
\end{itemize}

\subsection{Lab03--Lab05}
\begin{itemize}
    \item \textbf{Проверка количества файлов.} Запустить токенизацию и убедиться, что программа обработала все файлы из \texttt{data\_text} (количество обработанных файлов совпадает с количеством текстовых документов).
    \item \textbf{Проверка статистики.} Проверить, что в выводе есть осмысленные значения: общее число токенов больше нуля, средняя длина токена выглядит адекватно, время работы и скорость рассчитаны.
    \item \textbf{Сравнение токенизации и стемминга.} Запустить стемминг и убедиться, что средняя длина токена немного уменьшилась, а время стало больше (это ожидаемо).
    \item \textbf{Построение Ципфа.} Построить частотное распределение терминов и график в log-log масштабе. Проверить, что график выглядит как типичная ``почти прямая линия'' на среднем участке и не превращается в случайный шум.
    \item \textbf{Визуальная проверка.} На всякий случай открыть пару частотных слов вручную (например, топ-20) и убедиться, что там находятся действительно часто встречающиеся термины, а не мусор.
\end{itemize}

\subsection{Lab07--Lab08}
\begin{itemize}
    \item \textbf{Проверка сборки индекса.} После построения индекса проверить наличие файлов \texttt{docs.tsv}, \texttt{dict.tsv}, \texttt{postings.bin} и что они не нулевого размера.
    \item \textbf{Проверка простых запросов.} Протестировать несколько запросов без скобок и убедиться, что поиск даёт ожидаемый результат (например, AND даёт меньше результатов, чем OR).
    \item \textbf{Проверка скобок и приоритетов.} Сравнить результаты для \texttt{a AND b OR c} и \texttt{a AND (b OR c)}, чтобы убедиться, что скобки реально влияют на порядок вычисления.
    \item \textbf{Проверка NOT.} Протестировать запрос вида \texttt{ship AND NOT war} и убедиться, что документы со словом \texttt{war} исключаются.
    \item \textbf{Пустая выдача.} Проверить запрос, который почти наверняка не встретится, и убедиться, что программа корректно сообщает 0 результатов и не падает.
    \item \textbf{CLI vs Web.} Для одинакового запроса сравнить результаты командной строки и веб-интерфейса (по количеству hits и по нескольким первым документам).
\end{itemize}
